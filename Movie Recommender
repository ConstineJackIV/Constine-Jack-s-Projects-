# https://www.kaggle.com/tmdb/tmdb-movie-metadata # Link to data set of movies 
import requests

url = 'https://lazyprogrammer.me/course_files/nlp/tmdb_5000_movies.csv'
response = requests.get(url)

with open('tmdb_5000_movies.csv', 'wb') as f:
    f.write(response.content)

import pandas as pd
import matplotlib.pyplot as plt
import json # Need json library due to some info being in json format

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances

df = pd.read_csv('tmdb_5000_movies.csv') # read in our data
df.head() # See whats inside data frame 

x = df.iloc[0] # Retrive first row of data, this prints out panda series with the col names and values
x 

x['genres'] # Print out the genres col

x['keywords'] # Another col to build our text 

j = json.loads(x['genres']) # Convert json string into a formate usable in python. Python list of python dictionaries
j

' '.join(''.join(jj['name'].split()) for jj in j) # Run through each item in the list, take the value in the name attribute, then concatinate if the genre is two words. That way we get something like "ScienceFiction, Romance, Adventure"

# convert the relevant data for each movie into a single string
# to be ingested by TfidfVectorizer
def genres_and_keywords_to_string(row):
  genres = json.loads(row['genres'])
  genres = ' '.join(''.join(j['name'].split()) for j in genres)

  keywords = json.loads(row['keywords'])
  keywords = ' '.join(''.join(j['name'].split()) for j in keywords)
  return "%s %s" % (genres, keywords) # Return genres and keywords together into a single string 

# create a new string representation of each movie
df['string'] = df.apply(genres_and_keywords_to_string, axis=1) # run function on all rows in data frame, assign to new col called string  

# create a tf-idf vectorizer object
tfidf = TfidfVectorizer(max_features=2000) # Keep most freq words in corpus 

# create a data matrix from the overviews
X = tfidf.fit_transform(df['string']) 
X

# generate a mapping from movie title -> index (in df)
movie2idx = pd.Series(df.index, index=df['title']) # Points towards movie name and its value 
movie2idx

idx = movie2idx['Star Wars'] # Gives index of where movie is stored 
idx

query = X[idx] # 
query

# print the query vector
query.toarray() # see the values held within the function 

# compute similarity between query and every vector in X
scores = cosine_similarity(query, X) # Finding the simularities from one movie to another
scores

# currently the array is 1 x N, make it just a 1-D array
scores = scores.flatten()
plt.plot(scores); # Gives visuals of similarites 

(-scores).argsort() # We sort in descending order as we want to return the top 5 most similary movies, argsort is more accurate as it tells use the movies based on the score

plt.plot(scores[(-scores).argsort()]); # Visual of descending movies

# get top 5 matches
# exclude self (similarity between query and itself yields max score)
recommended_idx = (-scores).argsort()[1:6]
# convert indices back to titles
df['title'].iloc[recommended_idx]

# create a function that generates recommendations
def recommend(title):
  # get the row in the dataframe for this movie
  idx = movie2idx[title]
  if type(idx) == pd.Series:
    idx = idx.iloc[0]

  # calculate the pairwise similarities for this movie
  query = X[idx]
  scores = cosine_similarity(query, X)

  # currently the array is 1 x N, make it just a 1-D array
  scores = scores.flatten()

  # get the indexes of the highest scoring movies
  # get the first K recommendations
  # don't return itself!
  recommended_idx = (-scores).argsort()[1:6]

  # return the titles of the recommendations
  return df['title'].iloc[recommended_idx]
print("Recommendations for 'Scream 3':")
print(recommend('Scream 3'))

print("Recommendations for 'Mortal Kombat':")
print(recommend('Mortal Kombat'))

print("Recommendations for 'Runaway Bride':")
print(recommend('Runaway Bride'))
